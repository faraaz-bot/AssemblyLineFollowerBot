This project focused on programming an HCS12 EEBOT robot using Assembly language to autonomously navigate a complex maze. The robot was engineered to follow a single black line as its primary guide while implementing logic to detect and avoid dead ends or barriers, ensuring a smooth path from the maze's starting point to its endpoint. The task required a thorough understanding of sensor integration, control algorithms, and coding in Assembly to achieve precise movements and reliable decision-making. By combining these elements, the project aimed to demonstrate the practical application of embedded systems and low-level programming in robotics.

The EEBOT robot is equipped with an HCS12 microcontroller and multiple input devices to navigate through the maze. These include a front and rear bumper, as well as five line sensors located at the bottom of the robot.The EEBOT is also equipped with output devices, such as motors and a LCD display, which work with the input from sensors and the programmed logic to guide the robot's movements.

The bumpers detect dead ends by triggering a subroutine when activated. This subroutine initiates a U-turn, enabling the robot to backtrack and take the alternate path at the intersection. The robot’s decision-making process is guided by a state machine/dispatcher that holds information about the current state and the conditions that cause it to change state. This approach ensured that the robot consistently chose the correct path without deviating or retracing incorrect steps.

The line sensors consist of five photoresistors and accompanying LED’s, which detect the black line forming the maze path. These sensors guide the robot forward as long as the black line is detected and within the center of the bot. At intersections, the robot uses the sensor data to detect a split in the “road”, turning always to the left side. It achieves this by calling the subroutine for a left turn. This mechanism ensured the robot stayed on track within the maze, preventing it from veering off-course. This approach of always turning left resulted in slower navigation but it successfully met the project’s objective.

Additional code was written to integrate line-following logic and handle event-based subroutine calls, such as those for dead-end detection and intersection handling. Furthermore, a section of the code was dedicated to displaying the robot’s current state, allowing insight into its operational status during navigation which was crucial for debugging problems. A significant amount of code was reused from Labs 1 - 6, which include code for hardware delays, LCD display initialization, Motor initialization, motor control, bumper control, and state machine/dispatcher. 
